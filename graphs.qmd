---
title: "Visualising data in R: A primer"
author: "Jan Vanhove"
date: "Fribourg, 14 March 2025"
format:
  html:
    theme: flatly
    toc: true
    number-sections: true
    code-line-numbers: false
    df-print: paged
    fig-format: svg
    self-contained: true
editor: source
bibliography: bibliography.bib
---

# Goal
The goal of this primer is to present the techniques for visualising
research data that I have found to be most useful and to show to you
how you can use R, and specifically the `ggplot2/tidyverse` package,
to draw informative plots.
The focus is on drawing plots of raw data 
as opposed to visualising statistical models.
If you want to learn more about visualising statistical models, 
you can check out my tutorial 
[_Visualising statistical uncertainty using model-based graphs_](https://janhove.github.io/visualise_uncertainty/).
I also decided to leave out plot types that are not easy to interpret properly
for audiences without a considerable amount of statistical know-how
such as kernel density estimates and quantile--quantile plots.

::: {.callout-tip}
## Type, don't copy-paste -- at home
You're going to take away much more from this primer
if you copy the code snippets by _typing_ them rather
than by copy-pasting them.
That said, I strongly advise you to do so in your own
time and not as you're attending the lecture:
Some things are bound to go wrong (perhaps a comma
in the wrong spot, a missing bracket or an upper-case
letter that should have been a lower-case one), and
as you're trying to fix the errors, you'll lose track of the lecture.

So work through the code snippets at home, and be patient with yourselves.
:::

# Preliminaries
## Required packages
We'll need the `here` and `tidyverse` packages; install these packages if you
don't have them already.

The `here` package makes it easier to read in data and save objects (datasets,
figures).
The `tidyverse` suite contains the `ggplot2` package, which we'll use
extensively here.

### Setting up an R project
Next, in RStudio, click on `File > New Project... > New Directory`. 
Navigate to somewhere on your computer where you want to create a new directory
and give this directory a name (for instance, `DatasetsAndGraphs`). You will use this
directory to store the data and scripts that you'll need for drawing the graphs
in as well for saving the graphs themselves to. You don't have to tick the other options.

When you're done, close RStudio. Navigate to the directory you've just created.
You should find an `.Rproj` file there. Double-click it. If all is well, RStudio
should fire up.

Create the following subdirectories in the directory you're currently in:
`data`, `scripts` and `figs`.

On [github.com/janhove/DatasetsAndGraphs](https://github.com/janhove/DatasetsAndGraphs),
you can find a couple of datasets (under `data`) as well as an R script 
that defines a new function we'll use (under `functions`). Put the datasets in your
own `data` directory and the R script in your own `functions` directory.

## Loading the packages
Load the `here` and `tidyverse` packages.

```{r}
library(here)
library(tidyverse)
```


# Histograms
The file `Vanhove2015_Vpn.csv` contains a couple of pieces of information 
about the participants in an experiment
that I conducted several years ago [@Vanhove2016]: 
`ID`, scores on German, English and French vocabulary tests (`Wortschatz`, 
`Englisch` and `Französisch`, respectively), sex (`Geschlecht`), and age 
(`Alter`).
Make sure that this file is stored in the `data` subdirectory of the
R project you created.
Now read in the data as explained in the primer on working with datasets.

```{r}
d_hist <- read_csv(here("data", "Vanhove2015_Vpn.csv"))
```

A histogram shows how a single numeric variable is distributed ('univariate distribution').
The range of the observed values of this variable is split up in a number
of intervals, typically all of equal width. 
Over each interval, a bar is drawn whose height reflects how often the 
variable takes on values in this interval.
In the simplest version, the height of the bar corresponds to the _number_ 
of times the variable falls in the interval, but we'll encounter a slightly
more complicated (but sometimes more useful) version shortly.

Histograms are particularly useful to check if 
there are any 'univariate' outliers (i.e., values that lie far from the bulk of the data if you consider only this one variable) and to see if the variable seems to be distributed approximately uniformly, normally, bimodally or more wonkily.

Since you've already loaded the `tidyverse` and since you've already read in the data, we can start to draw some histograms.
To this end, we need to define the object and the variables we want to plot (lines 1--2). 
If we only executed the first two lines of the code below, all we'd see is a blank canvas.
To draw the histogram itself, we need to add a **layer** to this blank canvas that
contains a histogram based on these pieces of information.

```{r}
ggplot(data = d_hist,       # specify data set
       aes(x = Englisch)) + # variable to be drawn
  geom_histogram()          # draw as histogram
```

Alternatively, you can use the pipe (`|>`) to pass the tibble to the
`ggplot()` function. This is merely a matter of personal preference.

```{r, eval = FALSE}
d_hist |> 
  ggplot(aes(x = Englisch)) +
  geom_histogram()
```

::: {.callout-caution}
## `|>` vs. `+`

Different layers of a `ggplot()` figure are strung together using `+`, 
whereas `|>` is used outside of the `ggplot()` code proper to relay
an object to the next function.
:::

The histogram shows, among other things, that there are 8 individuals with an English vocabulary score just below 0.7 and 4 with a score just below 0.6. By default, 30 such _bins_ are drawn, but as the warning indicates ('Pick better value'), there's nothing special about this number. You can adjust the desired bin width:

```{r}
ggplot(data = d_hist,
       aes(x = Englisch)) +
  geom_histogram(binwidth = 0.2) # binwidth of 0.2 points

ggplot(data = d_hist,
       aes(x = Englisch)) +
  geom_histogram(binwidth = 0.1) # binwidth of 0.1 points

ggplot(data = d_hist,
       aes(x = Englisch)) +
  geom_histogram(binwidth = 0.05) # binwidth of 0.05 points

ggplot(data = d_hist,
       aes(x = Englisch)) +
  geom_histogram(binwidth = 1/30) # binwidth of 1/30 points
```

Clearly, the shape of the histogram depends crucially on how the bins were chosen.
There aren't any hard and fast rules for determining the optimal bin width. 
The default settings (1st plot) produce a histogram that seems to be a bit too fine-grained, 
whereas a bin width of 0.2 (2nd plot) results in too coarse a histogram. 
The other three histograms seem fine by me; 
I'd probably pick the 4th or 5th for a presentation or when writing a paper.

Alternatively, you can specify the number of bins or you can define the bins yourself:

```{r}
ggplot(data = d_hist,
       aes(x = Englisch)) +
  geom_histogram(bins = 10) # use 10 bins

ggplot(data = d_hist,
       aes(x = Englisch)) +
  geom_histogram(breaks = seq(0.45, 0.9, 0.05)) # define break boundaries manually
```

The bins don't need to all be of the same size, but they usually are.

Incidentally, the intervals are, by default, open to the left
and closed to the right. That is, if we have bins (0.6, 0.7] and (0.7, 0.8], 
the value 0.7 is counted in the bin (0.6, 0.7] and not in (0.7, 0.8].

The histograms we've already drawn are probably sufficient for our
own private use. But if we wanted to use these histograms in a presentation
or in a publication, we ought to make some further changes. 

First, use `xlab()` and `ylab()` to label axes. Don't forget the quotation marks.

```{r}
ggplot(data = d_hist,
                 aes(x = Englisch)) +
  geom_histogram(binwidth = 0.05) +
  xlab("English vocabulary score") +
  ylab("Number of participants")
```

Important:

```{r, echo = FALSE, fig.cap = "Source: https://xkcd.com/833/."}
knitr::include_graphics("https://imgs.xkcd.com/comics/convincing.png")
```

Next, add a title and, if needed, a subtitle and a caption. See `?labs` for further
options.
```{r}
ggplot(data = d_hist,
                 aes(x = Englisch)) +
  geom_histogram(binwidth = 0.05) +
  xlab("English vocabulary score") +
  ylab("Number of participants") +
  labs(
    title = "The participants' English vocabulary scores",
    subtitle = "(some subtitle if needed)",
    caption = "English vocabulary scores were obtained using the LexTALE test."
  )
```

I don't really like the default colours, but we can easily override those:

```{r}
ggplot(data = d_hist,
                 aes(x = Englisch)) +
  geom_histogram(binwidth = 0.05,
                 fill = "lightgrey",
                 colour = "black") +
  xlab("English vocabulary score") +
  ylab("Number of participants") +
  labs(
    title = "The participants' English vocabulary scores",
    subtitle = "(some subtitle if needed)",
    caption = "English vocabulary scores were obtained using the LexTALE test."
  )
```

You can also apply one of the `ggplot2` themes, see the [ggplot2 documentation](https://ggplot2.tidyverse.org/reference/ggtheme.html).
For instance,

```{r}
ggplot(data = d_hist,
                 aes(x = Englisch)) +
  geom_histogram(binwidth = 0.05,           
                 fill = "lightgrey",
                 colour = "black") + 
  xlab("English vocabulary score") +
  ylab("Number of participants") +
  labs(
    title = "The participants' English vocabulary scores",
    subtitle = "(some subtitle if needed)",
    caption = "English vocabulary scores were obtained using the LexTALE test."
  ) +
  theme_bw()
```


::: {.callout-note}
## Saving figures
If the last figure was drawn using `ggplot()`, we can save it 
using `ggsave()`. The following command saves the figure as a PNG file,
but other common formats such as PDF, BMP, SVG, JPEG and TIFF are supported
as well. You can also specify the dimensions and other details, see
`?ggsave`.

```{r}
ggsave(here("figs", "histogram_english.png"))
```

Alternatively, we can save the figure by enclosing the code
to draw it between a call to `pdf()`, `png()` or a couple of
other options, and one to `dev.off()`, like so:
```{r}
pdf(here("figs", "histogram_english.pdf"))
ggplot(data = d_hist,
                 aes(x = Englisch)) +
  geom_histogram(binwidth = 0.05,           
                 fill = "lightgrey",
                 colour = "black") + 
  xlab("English vocabulary score") +
  ylab("Number of participants") +
  labs(
    title = "The participants' English vocabulary scores",
    subtitle = "(some subtitle if needed)",
    caption = "English vocabulary scores were obtained using the LexTALE test."
  ) +
  theme_bw()
dev.off()
```

See `?pdf` for details. Related functions are `png()`, `tiff()`, `svg()` etc.
:::

In order to faciliate comparisons of different histograms
(e.g., histograms for different subsets of the data, or histograms
of the same data but using different bin widths), what's often plotted
along the y-axis isn't the _number_ of data points in each interval,
but a so-called **density estimate**. To this end, the y-axis is scaled in such a way
that the total _area_ covered by the histogram is equal to 1.
Use `y = after_stat(density)` to plot density estimates rather than counts:

```{r}
ggplot(data = d_hist,
                 aes(x = Englisch,
                     y = after_stat(density))) +
  geom_histogram(binwidth = 0.05,           
                 fill = "lightgrey",
                 colour = "black") +
  xlab("English vocabulary score") +
  ylab("density")
```

We can verify that
$$0.05 \times (0.5 + 1.5 + 5 + 4.5 + 3.5 + 2.75 + 1.5 + 0.75) = 1.$$

If we were to express the English vocabulary scores on a scale
from 0 to 10 rather than from 0 to 1 and use bins of width 0.5 points
rather than of width 0.05 points, the density estimates would be a tenth
of what they are now. 
This is because, if we're using density estimates, the area covered by the histogram
needs to equal 1.

::: {#exr-histogram}
## A histogram
Draw a suitable histogram for the `Französisch` variable as well as for the 
`Wortschatz` variable in the `d_hist` dataset. 
This will require you to tinker with the `binwidth` setting. 
Don't forget to adjust the axis labels. 
Use `ggsave()` to save your preferred histogram for each of the two variables
as an SVG file.
:::

::: {.callout-note}
## On probability densities
The reason why histograms sometimes represent so-called density estimates
rather than, say, the proportion of observations that fall in each bin is this.
The distribution of a continuous variable $X$ can be described by its 
**probability density**. This is a non-negative function $f$ with the property
that
$$\mathbb{P}(X \in [a,b]) = \int_{a}^b f(t) ~\textrm{d}t$$
for all $a \leq b$.
Or in words, the probability that $X$ takes on a value in the interval $[a,b]$
corresponds to the area underneath the function graph (= integral) between the values $a$ and $b$.
Since $\mathbb{P}(X \in (-\infty, \infty)) = 1$, the area underneath the whole graph
should equal 1.

For instance, the distribution of IQ values can be modelled as a normal distribution
with mean 100 and standard deviation 15. The plot below shows the probability density
function of this distribution. To compute the probability that a randomly picked
person has an IQ between 92 and 103, we can compute the size of the shaded area.
```{r, echo = FALSE}
mean_val <- 100
sd_val <- 15
x_vals <- seq(mean_val - 4 * sd_val, mean_val + 4 * sd_val, length.out = 1000)
density_vals <- dnorm(x_vals, mean = mean_val, sd = sd_val)
df <- data.frame(x = x_vals, y = density_vals)
shade_df <- df[df$x >= 92 & df$x <= 103, ]
ggplot(df, aes(x, y)) +
  geom_line(color = "black", linewidth = 1) +  # Density curve
  geom_ribbon(data = shade_df, aes(ymin = 0, ymax = y), fill = "grey10", alpha = 0.4) +  # Shaded area
  labs(x = "x", y = "Density") +
  theme_minimal()
```

Histograms can be thought of as estimators of the probability density function
of the distribution from which the observed values were sampled.
Other types of plots that serve this purpose exist (kernel density estimation),
but I don't think these are too useful in an introduction such as this.
Further note that only continuous distributions have probability densities.
(By definition, $X$ has a continuous distribution if $\mathbb{P}(X = x) = 0$
for all real numbers $x$. )
:::

# Boxplots
The file `VowelChoices_ij.csv`
contains a part of the results
of a learning experiment [@Vanhove2016]
in which 80 participants were randomly assigned to one
of two learning conditions (`LearningCondition`: `<oe> participants` and `<ij> participants`).
The column `PropCorrect` contains the proportion 
of correct answers for each participant,
and the question we want to answer concerns
the difference in the performance between
learners in the different conditions. We'll use these data to introduce
boxplots.

```{r}
d_box <- read_csv(here("data", "VowelChoices_ij.csv"))
```

Below you see a basic boxplot of the vocabulary test scores of the
eighty participants in the same learning experiment.
The **median** score is highlighted by a thick line.
The 25th and 75th percentiles are highlighted by thinner lines and together
form a box. The difference between the 75th and 25th percentile 
(also known as the third and the first quartile) is
called the **inter-quartile range (IQR)**.
The data points that don't fall in the box, that is, the data points that don't
make up the middle 50% of the data, are represented by a line protruding from
the upper part of the box and by a line protruding from the lower part of the box.
However, data points whose distance to the box exceeds 1.5 times the inter-quartile
range are plotted separately. If such data points exist, the lines protruding from 
the box only extend up to the lowest / highest data point whose distance to the 
box is lower than 1.5 times the IQR.

::: {.callout-note}
## Quantiles, percentiles, median?
Let $X = (X_1, \dots, X_n)$ be a data vector and let $\alpha \in (0,1)$.
We say that a value $q_{\alpha}$ is an $\alpha$ **quantile** (or a $100\alpha$th **percentile**) of the $X$
if at least $\alpha \cdot n$ values in $X$ are no greater than $q_{\alpha}$
and at most $(1-\alpha) \cdot n$ values in $X$ are no smaller than $q_{\alpha}$.
For instance, the boxplot below shows that 34 is a 0.75 quantile (or 75th percentile)
of the vocabulary scores. Indeed, we can verify that at least 75% (in fact 78.75%) of the 
vocabulary scores are no greater than 34 and that at least 25% (in fact 38.75%)
of them are no smaller than 34.

```{r, echo = FALSE, message = FALSE}
dat <- read_csv(here("data", "Vanhove2015_Vpn.csv"))
```


```{r}
mean(dat$Wortschatz <= 34)
mean(dat$Wortschatz >= 34)
```
Note that it is _not_ the case that _exactly_ $100\alpha$% of the observations
are no greater than any given $\alpha$ quantile. Moreover, quantiles aren't 
necessarily uniquely defined. For instance, 28.4 is a 0.075 quantile of the vocabulary
scores. But so is 28.
```{r}
mean(dat$Wortschatz <= 28.4) # at least 0.075
mean(dat$Wortschatz >= 28.4) # at least 0.925

mean(dat$Wortschatz <= 28)   # at least 0.075
mean(dat$Wortschatz >= 28)   # at least 0.925
```

When we talk about _the_ (as opposed to _an_) $\alpha$ quantile,
we mean the average of all the $\alpha$ quantiles.

A median is merely a $0.5$ quantile. _The_ median is the average 
of all $0.5$ quantiles. In practice, this boils down to the average of
the smallest and the largest such quantile.

(The discussion above assumes that we are interested in the empirical
distribution of the values in the data vector $X$ rather than in estimating
the quantiles of the distribution from which $X$ was sampled.
For our present purposes, this is more than sufficient.
But see the explanation `?quantile` for details.)
:::

From the boxplot below, we can glean that the IQR is $34 - 31 = 3$.
The highest data point has a value of 38. Since $38 < 34 + 1.5 \times 3 = 38.5$,
this data point is captured by the line protruding from the upper part of the box.
The lowest data point has a value of 25. Since $25 < 31 - 1.5 \times 3 = 26.5$,
it lies too far from the box to be captured by the line protruding from the lower
part of the box, so it gets drawn separately.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
dat <- read_csv(here("data", "Vanhove2015_Vpn.csv"))
old_ops <- par()
par(mar = c(1, 4, 2, 1), las = 1, cex = 1.3)
boxplot(dat$Wortschatz, boxwex = 0.25, staplewex = 0,
        ylab = "Vocabulary test score", col = "white",
        main = "Example boxplot", pars = list(boxwex=0.4), at=0.3, xlim=c(0.15,0.55))
text(x = 0.45, max(dat$Wortschatz), "Maximum")
text(x = 0.45, quantile(dat$Wortschatz, .75), "75th percentile", font=3)
text(x = 0.45, median(dat$Wortschatz), "Median", font=2)
text(x = 0.45, median(dat$Wortschatz)-0.8, "(= 50th percentile)")
text(x = 0.45, quantile(dat$Wortschatz, .25), "25th percentile", font=3)
text(x = 0.45, 27, "'Minimum'")
text(x = 0.43, 25.5, "Data points more than\n1.5*IQR from the box")
par(old_ops)
```

We can draw boxplots in order to compare the distribution of a variable
in two groups.
But you can also use
boxplots to compare more than two groups.

The following command plots the accuracy
data (`PropCorrect`) using a separate boxplot for
each condition (`LearningCondition`). 
We also add axis labels and change the plotting theme:

```{r, fig.asp = 0.6}
ggplot(data = d_box,              
       aes(x = LearningCondition, 
           y = PropCorrect)) +    
  geom_boxplot() +
  xlab("Learning condition") +
  ylab("Proportion of correct translations") +
  theme_bw()
```

Plain boxplots are useful when 
you want to get a quick idea of the distribution
of the data in different groups.
However, identically looking boxplots can represent markedly different distributions!
Furthermore, as the next exercise may illustrate, boxplots may be hard to interpret at first blush.

::: {#exr-distributions}
## Matching boxplots to histograms
For the plot below, I generated data from five different distributions.
For each generated dataset, I drew a histogram and a boxplot.
Match the histograms and the boxplots that are drawn on the basis of the same data.
Are there any pecularities of the data distributions that are visible in the
histogram but not in the boxplot?
```{r, echo = FALSE, fig.width = 6, fig.height = 12}
set.seed(2025-10-02)
d1 <- c(rbeta(40, 20, 1), rbeta(40, 1, 20))
d2 <- rbeta(80, 3, 3)
d3 <- c(rbeta(40, 15, 40), rbeta(40, 40, 15))
d4 <- round(rbeta(80, 3, 3) * 7) / 7
d5 <- rbeta(80, 3, 1)
df <- data.frame(d1, d2, d3, d4, d5)

h1 <- ggplot(df, aes(x = d1, y = after_stat(density))) +
  geom_histogram(breaks = seq(0, 1, by = 0.1), colour = "black", fill = "grey") +
  xlab("x") +
  xlim(0, 1) +
  theme_bw()

h2 <- ggplot(df, aes(x = d2, y = after_stat(density))) +
  geom_histogram(breaks = seq(0, 1, by = 0.1), colour = "black", fill = "grey") +
  xlab("x") +
  xlim(0, 1) +
  theme_bw()

h3 <- ggplot(df, aes(x = d3, y = after_stat(density))) +
  geom_histogram(breaks = seq(0, 1, by = 0.1), colour = "black", fill = "grey") +
  xlab("x") +
  xlim(0, 1) +
  theme_bw()

h4 <- ggplot(df, aes(x = d4, y = after_stat(density))) +
  geom_histogram(breaks = seq(0, 1, by = 0.1), colour = "black", fill = "grey") +
  xlab("x") +
  xlim(0, 1) +
  theme_bw()

h5 <- ggplot(df, aes(x = d5, y = after_stat(density))) +
  geom_histogram(breaks = seq(0, 1, by = 0.1), colour = "black", fill = "grey") +
  xlab("x") +
  xlim(0, 1) +
  theme_bw()

b1 <- ggplot(df, aes(x = "", y = d1)) +
  geom_boxplot() +
  xlab(element_blank()) +
  ylab("x") +
  ylim(0, 1) +
  theme_bw()

b2 <- ggplot(df, aes(x = "", y = d2)) +
  geom_boxplot() +
  xlab(element_blank()) +
  ylab("x") +
  ylim(0, 1) +
  theme_bw()

b3 <- ggplot(df, aes(x = "", y = d3)) +
  geom_boxplot() +
  xlab(element_blank()) +
  ylab("x") +
  ylim(0, 1) +
  theme_bw()

b4 <- ggplot(df, aes(x = "", y = d4)) +
  geom_boxplot() +
  xlab(element_blank()) +
  ylab("x") +
  ylim(0, 1) +
  theme_bw()

b5 <- ggplot(df, aes(x = "", y = d5)) +
  geom_boxplot() +
  xlab(element_blank()) +
  ylab("x") +
  ylim(0, 1) +
  theme_bw()

library(patchwork)
(h3 + b2) /
  (h5 + b4) /
  (h2 + b1) /
  (h1 + b3) /
  (h4 + b5)
```

:::

To make boxplots more informative and easier to interpret,
it can be useful to draw boxplots
that also show the _individual_ data points rather
than merely the distribution's quartiles.
Such visualisations are particularly useful
when the dataset isn't prohibitively large,
so that you can actually make out the different data points.

To do so, we can another _layer_ to the boxplot by
inserting the command `geom_point()` into the ggplot call. 
`geom_point()` draws the data points as, well, points 
and doesn't summarise its quartiles like `geom_boxplot()` does. 
Since we insert `geom_point()` _after_ `geom_boxplot()`, 
these points will be plotted _on top of_ (rather than underneath) the boxplots.

```{r}
ggplot(data = d_box,
       aes(x = LearningCondition, y = PropCorrect)) +
  geom_boxplot() +
  geom_point() +    # draw individual data points
  xlab("Learning condition") +
  ylab("Proportion correct answers") +
  theme_bw()      
```

If you count the number of points in the graph above, 
you'll notice that there are much fewer points (28) than there were participants (80). 
The reason is that several participants obtained the same result, 
and their data are plotted on top of each other. 
For this reason, it makes sense to move the plotted points a bit apart (_jittering_). 
Here we can move the points apart horizontally. 
To do this, we need to specify the `position` parameter inside the `geom_point()` command.

* We can specify both `width` (horizontal jittering) and `height` (vertical jittering). Fiddle with the setting for `width` to see what happens if you change it. I'd leave the value for `height` set to 0 (= no vertical jittering) so that we don't depict proportions of, say, 0.24 as 0.28.
* Notice that I've additionally specified the `outlier.shape` parameter in the `geom_boxplot()` command as `NA` (_not available_). This prevents the `geom_boxplot()` command from plotting outlying data points so that these points aren't plotted twice (as part of the boxplot and as an individual data point).

```{r}
ggplot(data = d_box,
       aes(x = LearningCondition, 
           y = PropCorrect)) +
  geom_boxplot(outlier.shape = NA) + # don't plot outliers twice
  geom_point(position = position_jitter(width = 0.2,   # horizontal jittering
                                        height = 0)) + # but no vertical jittering
  xlab("Learning condition") +
  ylab("Proportion correct answers") +
  theme_bw()
```


To make the individual data points more visually distinct, we can change the plotting symbol by changing the `shape` parameter. This overview shows which plotting symbols are available:

```{r, echo = FALSE, fig.asp = 1/4}
par(bty = "n", cex.lab = 0.6, mar = c(0, 0, 0, 0))
plot(x = 0:25, y = rep(1.1, 26), pch = 0:25, 
     yaxt = "n", ylab = "",
     ylim = c(0.5, 1.5),
     xaxt = "n", xlab = "shape")
text(x = 0:25, y = rep(0.9, 26), labels = as.character(0:25))
```

Empty circles tend to work well (shape 1):

```{r}
ggplot(data = d_box,
       aes(x = LearningCondition, 
           y = PropCorrect)) +
  geom_boxplot(outlier.shape = NA) + 
  geom_point(position = position_jitter(width = 0.2,   
                                        height = 0), 
             shape = 1) + #  1 = empty circles
  xlab("Learning condition") +
  ylab("Proportion correct answers") +
  theme_bw(12)
```

Shapes 21 through 25 resemble shapes 1 through 5, but they can be coloured in.

::: {#exr-boxplot}
## A boxplot
@Wagenmakers2016 set out to replicate
an older study across a large number of psychology labs.
The dataset `Wagenmakers_Zeelenberg.csv` contains summary data from one such lab (Zeelenberg et al.).
In the experiment, participants were instructed to either `smile` or `pout` (`Condition`)
as they judged the funniness of four cartoons on a 10-point scale (0--9).
The mean rating per participant can be found in the creatively named column `MeanRating`.
The research question was if smiling participants gave higher funniness ratings than pouting ones.

Compute the number of participants in each condition as well as 
the mean `MeanRating` per condition (see the previous primer). 
Also draw boxplots (with individual data points) on the basis of 
which this research question
can be answered. Label your axes appropriately. 
Save a graph you're happy with
using `ggsave()`.
:::

::: {#exr-datawrangling}
## Another boxplot and some data wrangling
You can find the data from all labs involved in the @Wagenmakers2016
replication attempt on [https://osf.io/hgi2y/](https://osf.io/hgi2y/).
Locate and download the data from any of the labs (other than the Zeelenberg et al. one).
Inspect the dataset using a spreadsheet program and note how the data are laid out.
In particular, observe that the data entries start in row 3 as opposed to row 2.
The funniness ratings are in columns K through N, whereas columns D through H
indicate whether the participants followed the instruction. Column C shows
which condition the participants were assigned to.
Using R only (i.e., don't use your spreadsheet program for the next steps),
do the following:

1. Read in the data. (The `skip` parameter of the `read_csv()` function may be useful.)
2. Create a tibble that contains the mean funniness ratings assigned by each participant that followed the instructions on all four cartoons. This tibble should, at the very least, contain a column indicating the condition the participants were assigned to and the mean funniness rating they gave to the four cartoons. Participants who did not follow the instructions all the time should not be included. It's probably a good idea to label the conditions `pout` and `smile` rather than `0` and `1`.
3. Compute the number of participants with usable data in each condition as well as the mean average funniness rating per condition. 
4. Draw boxplots (with individual data points) on the basis of which this research question
can be answered. Label your axes appropriately. Save a graph you're happy with
using `ggsave()`.
:::

::: {.callout-note}
## Comparing groups using frequency polygons or empirical cumulative density functions
It's possible to compare the distribution of some variable
across two or more groups using
**frequency polygons**, too. These are constructed similarly to histograms,
but without the bars being drawn. See the code below. Depending on how many bins
are drawn and where their boundaries are, these frequency polygons may take
on different shapes.

```{r}
ggplot(data = d_box,
       aes(x = PropCorrect, 
           y = after_stat(density),
           colour = LearningCondition)) +
  geom_freqpoly(bins = 10)
```

Another possibility is to make use of so-called **empirical cumulative density functions**.
For a given data vector $X = (X_1, \dots, X_n)$, the empirical cumulative density
function outputs for each number $r$ the proportion of data points $X_i$ in $X$ 
such that $X_i \leq r$:

```{r}
ggplot(data = d_box,
       aes(x = PropCorrect,
           colour = LearningCondition)) +
  stat_ecdf() +
  ylab("empirical cumulative density")
```

What may be counterintuitive at first blush is that the line for the
<oe> participants is higher than the one for the <ij> participants.
On reflection, this makes sense: 
Looking up the value 0.5 on the x-axis,
we may deduce that about 62.5% of the <ij> participants have a `PropCorrect` value of 0.5 or below,
whereas more than 87.5% of the <oe> participants have a `PropCorrect` value of 0.5 or below.
So the group that tends to have the _lowest_ values 
should have _higher_ empirical cumulative density values!
This may go some way towards explaining why I don't recall ever having seen empirical cumulative
density plots outside of the statistical literature. That said, an attractive feature
of these plots is that they fully characterise the distribution of the observed data
and that they don't require you to fiddle with parameters such as the number of bins.
:::

::: {#exr-ecdf}
## Boxplots vs empirical cumulative density functions
For the plot below, I generated five datasets for two groups.
For each generated dataset, I drew boxplots and empirical cumulative density plots.
Match the boxplots and the empirical cumulative
density plots that are drawn on the basis of the same data.
Are there any pecularities of the data distributions that are visible in the
empirical cumulative density plots but not in the boxplot?
```{r, echo = FALSE, fig.width = 6, fig.height = 12}
set.seed(2025-02-11)
n <- 40
df <- data.frame(
  Group = rep(c("A", "B"), each = n),
  d1 = c(rnorm(n), rnorm(n, 1)),
  d2 = c(rbeta(n, 3, 3), rbeta(n, 1.2, 1.2)),
  d3 = c(rnorm(n), rnorm(n/2, -2), rnorm(n/2, 2)),
  d4 = c(rchisq(n, 3), rpois(n, 3)),
  d5 = c(rep(0, 15), rchisq(25, 2), rf(n, 1, 6))
)
normalise <- function(x) {
  x <- x - min(x)
  x / max(x)
}
df <- df |> 
  mutate_if(is.numeric, normalise)

b1 <- ggplot(df, aes(x = Group, y = d1)) +
  geom_boxplot() +
  ylab("outcome")

b2 <- ggplot(df, aes(x = Group, y = d2)) +
  geom_boxplot() +
  ylab("outcome")

b3 <- ggplot(df, aes(x = Group, y = d3)) +
  geom_boxplot() +
  ylab("outcome")

b4 <- ggplot(df, aes(x = Group, y = d4)) +
  geom_boxplot() +
  ylab("outcome")

b5 <- ggplot(df, aes(x = Group, y = d5)) +
  geom_boxplot() +
  ylab("outcome")

c1 <- ggplot(df, aes(x = d1, colour = Group)) +
  stat_ecdf() +
  xlab("outcome") +
  ylab("emp. cum. density fct.")

c2 <- ggplot(df, aes(x = d2, colour = Group)) +
  stat_ecdf() +
  xlab("outcome") +
  ylab("emp. cum. density fct.")

c3 <- ggplot(df, aes(x = d3, colour = Group)) +
  stat_ecdf() +
  xlab("outcome") +
  ylab("emp. cum. density fct.")

c4 <- ggplot(df, aes(x = d4, colour = Group)) +
  stat_ecdf() +
  xlab("outcome") +
  ylab("emp. cum. density fct.")

c5 <- ggplot(df, aes(x = d5, colour = Group)) +
  stat_ecdf() +
  xlab("outcome") +
  ylab("emp. cum. density fct.")

(b5 + c5) /
  (b4 + c2) /
  (b1 + c1) /
  (b3 + c3) /
  (b2 + c4)
```
:::

::: {.callout-tip}
## Try out alternative plots
Boxplots are a decent default choice for comparing groups.
But sometimes they obscure rather than reveal relevant differences
between groups, as shown in the previous exercises.
Furthermore, if the outcome data are fairly coarse, it may be more sensible
to plot the individual data points and highlight the mean instead of the median.

To illustrate this, we use data from an experiment by @Berthele2012.
The data are available in the file `berthele2012.csv`.
Skipping over the details, we'd like to know how the numeric variable `Potenzial`
varies depending on the values of the categorical variables `CS` and `Name`.
In the plot below, we use a technique called facetting to split up
the graph into two subgraphs. The boxplots don't seem to be too informative
as they are degenerate: The medians coincide with either the 1st or 3rd quartile
due to the coarseness of the data.
```{r}
berthele <- read_csv(here("data", "berthele2012.csv"))
ggplot(berthele,
       aes(x = CS, y = Potenzial)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(shape = 1, position = position_jitter(height = 0, width = 0.2)) +
  facet_grid(cols = vars(Name))
```

Instead of highlighting the medians and the quartiles, 
let's compute the mean `Potenzial` score as well as the standard deviation
for the `Potenzial` scores in each cell and add these to the data plot.
Note that we can pass new `data` arguments to geom-layers (here: `geom_pointrange()`)
in order to visualise data from different sources.
I also jittered the data points vertically ever so slightly in order to be able
to make out the overlapping data points better.
```{r}
potenzial_summary <- berthele |> 
  group_by(CS, Name) |> 
  summarise(mean_Potenzial = mean(Potenzial),
            sd_Potenzial = sd(Potenzial),
            .groups = "drop")

ggplot(berthele,
       aes(x = CS, y = Potenzial)) +
  geom_point(shape = 1, position = position_jitter(height = 0.05, width = 0.2)) +
  geom_pointrange(data = potenzial_summary,
             aes(y = mean_Potenzial, ymin = mean_Potenzial - sd_Potenzial,
                     ymax = mean_Potenzial + sd_Potenzial),
             size = 1, colour = "blue", shape = 8) +
  facet_grid(cols = vars(Name))
```

:::

# Line charts
Line charts are a reasonable choice for presenting
the results of more complex studies. They're often
used to depict temporal developments, but I don't
think their use should be restricted to this. I often
use line charts to better understand complex results
that are presented in a table. For instance, 
@Slavin2011
presented their results in four tables
(Tables 4--7). I entered the results pertaining 
to the PPVT (English) and TVIP (Spanish) post-tests
into a CSV file (`Peabody_Slavin2011.csv`):

```{r}
slavin <- read_csv(here("data", "Peabody_Slavin2011.csv"))
```

* `Grade`: Grades 1 through 4.
* `CourseType`: EI (English immersion) or TBE (transitional bilingual education).
* `Language`: English or Spanish.
* `Learners`: Number of learners per class, language and course type.
* `Mean`: Mean score per class, language and course type.
* `StDev`: Standard deviation per class, language and course type.

We can plot the development in the English and Spanish test scores
for the two course types:

```{r}
ggplot(data = slavin,
       aes(x = Grade, 
           y = Mean,
           colour = Language,        # use different colours per language
           linetype = CourseType)) + # use different line types per course type
  geom_line() + # connect data points with a line
  geom_point()  # add data points as points for good measure
```

What's new in the R code is that you can specify more than just an
`x` and a `y` parameter in the `aes()` call.
When you associate `colour` and `linetype` with variables
in the dataset, the data associated with different levels
of these variables (i.e., English vs. Spanish; TBE vs. EI)
will be plotted in a different colour or using a different
line type. The colours and line types used here are ggplot's
default choices; we could override those, see
`?scale_colour_manual` and `?scale_linetype_manual`.
The same goes for the appearance of the legends.

Using different colours and line types is all good and well
if you have a limited number of variables and a small number
of levels per variable. But for more complex data, such
graphs quickly become confusing. One useful technique
is to plot different lines in separate graphs (_small multiples_)
and show the different graphs side-by-side. This is known as **facetting**.
The command `facet_grid()` can be used to specify
the variables according to which the graph should be separated
and how.
Since the information regarding `Language` and `CourseType`
is expressed in the facets, we don't have to express it using
colours and linetypes any more. (But feel free to do so 
if you think it makes things clearer!) We need to quote the names
of the variables according to which the facets are to be drawn
in a `vars()` call.

```{r}
ggplot(data = slavin,
       aes(x = Grade,   
           y = Mean)) + 
  geom_line() +
  geom_point() +
  facet_grid(rows = vars(CourseType), # TBE vs. EI in rows; 
             cols = vars(Language))   # Span. vs. Eng. in columns
```

Or you can combine facetting with using different colours or line types.
In the next plot, the data for different languages are shown in separate
panels, but each panel shows the data for both the TBE and EI pupils.
This is particularly useful if we want to highlight differences (or similarities) 
between the TBE and EI pupils. If instead we wanted to highlight differences
or similarities in the development of the pupils' language skills in Spanish 
and English, we'd draw this graph the other way round.
In addition to connecting the means with a line, this graph also visualises
the means using a symbol in order to highlight that there were four discrete
measurement times (i.e., no measurements between Grades 1 and 2).

```{r}
ggplot(data = slavin,
       aes(x = Grade,
           y = Mean,
           shape = CourseType,       # different symbols by course type
           linetype = CourseType)) +
  geom_point() +
  geom_line() +
  facet_grid(cols = vars(Language)) # only split graph by column (Sp. vs. Eng.)
```

::: {.callout-warning}
## Averages don't tell the whole story
The line charts above only show the average PPVT and TVIP scores by
grade and course type as I don't have access to the raw data.
But averages don't always tell the whole story.

Consider the following example.
You're reading a study in which 39 participants answer a question on a scale
from 0 to 5. 
The study reports that the average response was 2.43 on this
6-point scale.
You would be forgiven for assuming that most participants answered '2' or '3'.
But this doesn't have to be the case: the three graphs below all
show 39 data points whose mean is 2.43 (after rounding). But we'd interpret
the left graph (only extreme choices) differently from the middle graph
(whole range of opinions) and from the right graph (only moderate responses).

```{r, echo = FALSE, fig.asp = 0.4}
op <- par(no.readonly = TRUE)
par(mfrow = c(1, 3), las = 1,
    oma = c(0, 0, 1, 0),
    bg = "white")

x <- c(20, 0, 0, 0, 0, 19)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Antwort",
        ylab = "Anzahl")

x <- c(7, 6, 4, 8, 13, 1)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Response",
        ylab = "Number")

x <- c(0, 0, 22, 17, 0, 0)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Response",
        ylab = "Number")
title("All graphs: mean =~ 2.43",
      outer = TRUE)
par(op)
```

If the reported results include a measure of dispersion (e.g., a standard deviation),
the number of possible data patterns is reduced, but there could nonetheless be a
**multitude of patterns** that give rise to the same numerical summaries but that
**may have to be interpreted differently**:

```{r, echo = FALSE}
par(mfrow = c(2, 3), las = 1,
    oma = c(0, 0, 1, 0),
    bg = "white")

x <- c(0, 0, 33, 0, 1, 5)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Response",
        ylab = "Number")


x <- c(0, 10, 7, 18, 3, 1)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Response",
        ylab = "Number")


x <- c(1, 10, 2, 23, 3, 0)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Response",
        ylab = "Number")


x <- c(0, 9, 11, 12, 7, 0)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Response",
        ylab = "Number")


x <- c(5, 1, 5, 28, 0, 0)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Response",
        ylab = "Number")


x <- c(3, 4, 7, 24, 0, 1)
names(x) <- 0:5
barplot(x, ylim = c(0, 40),
        xlab = "Response",
        ylab = "Number")

title("All graphs: mean =~ 2.43, SD =~ 1.05",
      outer = TRUE)
par(op)
```

A related reason for graphing the data is to make sure that the numerical
results reported are actually **relevant**. 
For instance, a study may report a difference in the mean outcomes of two
groups and illustrate this with the left panel in the figure below.
But if we look at the distribution of the raw data in both groups, shown
in the right panel, we realise that there is a strong right skew to these data.
This would prompt us to at least ask ourselves the question whether
we're at all interested in the _means_ of these groups.

```{r, echo = FALSE, fig.asp = 0.4, message = FALSE}
d <- read_csv(here("data", "Klein2014_gambler.csv"))
d <- subset(d, Sample == "ufl")
d <- subset(d, !is.na(RollsImagined))

par_original <- par(no.readonly = TRUE)
par(cex = 1.2, bty = "n",
    mar = c(2, 4, 0, 0), 
    mfrow = c(1, 2),
    tcl = -0.2,
    las = 1,
    cex.main = 1)
d$n.Condition <- as.numeric(factor(d$Condition))
d$y <- d$RollsImagined
means <- tapply(d$y, d$Condition, mean)

# Left plot
plot(x = c(1, 2),
     y = means,
     xaxt = "n",
     pch = 16, cex = 1,
     xlab = "",
     ylab = "mean outcome",
     ylim = c(15, 35),
     xlim = c(0.5, 2.5))
axis(side = 1, at = c(1, 2),
     labels = c("Group 1", "Group 2"))
segments(x0 = 1, x1 = 2,
         y0 = means[1], y1 = means[2],
         col = "black")

# Right plot
plot(x = jitter(d$n.Condition), y = d$y,
     xlim = c(0.5, 2.5),
     xaxt = "n",
     pch = 21, 
     col = "grey70", bg = "grey90",
     xlab = "predictor",
     ylab = "outcome")
axis(side = 1, at = c(1, 2),
     labels = c("Group 1", "Group 2"))
points(x = c(1, 2), y = means,
       pch = 8, cex = 2, col = "darkblue")
segments(x0 = 1, x1 = 2,
         y0 = means[1], y1 = means[2],
         col = "darkblue")
par(par_original)
```

For further discussion, see the blog post [_Before worrying about model assumptions, think about model relevance_](https://janhove.github.io/posts/2019-04-11-assumptions-relevance/) as well as the article @Vanhove2020b (preprint available from my website).

The upshot is this:
If at all possible, **don't just show averages** but try to give your readers
-- and yourselves --
a sense of how the actual data are distributed.
:::

::: {#exr-morphologicalcues}
## A line chart
The dataset `MorphologicalCues.csv` contains data stemming from a learning task in which the participants had to associate a morphological form with a syntactic function. 70 learners were randomly assigned to one of three conditions (`Condition`):

* `RuleBasedInput`: In this condition, the input showed a perfect association between the morphological form and the syntactic function.
* `StrongBias`: The input showed a strong, but imperfect association between form and function.
* `WeakBias`: The input showed a weak (but non-zero) association between form and function.

To track the learners' progress throughout the task, the learners took part in three sorts of exercises: 
`Comprehension`, grammaticality judgement (`GJT`) and 
`Production`. They did this at four stages during the data collection (`Block 1`, `2`, `3`, `4`), that is, after receiving a bit of input, some more input, etc.

The column `Accuracy` shows the mean percentage of correct responses per Block, per Task and per Condition.

The research question: How does `Accuracy` develop in the course of the data collection depending on the Task and Condition?

Plot these data so that the research question can be answered. You will want to try out several graphs so that you can pick a graph that you find most comprehensible.
:::

::: {#exr-schlechtweg1}
## Compute summary statistics and drawing a line chart
@Schlechtweg2023 investigated how well native speakers of German can tell
apart the English /ɛ/ (_pen_) and /æ/ (_pan_) vowels. In their first study,
they played a total of 198 recordings to each of their 51 participants
and asked them to identify whether the vowel sound contained in these recordings
was English /ɛ/ or English /æ/. The recordings differed in terms of their
spectral properties (formants 1 and 2) as well as in their duration.

The file `schlechtweg2023_selection.txt` contains the data for this task.
It contains the columns `Subject` (the participants' IDs),
`Item` (the minimal pair the recording belonged to),
`GermanPillai` (not relevant for this exercise),
`Duration` (`short`, `middle` or `long`),
`Step` (an integer between 1 and 11, with 1 representing a more
open and somewhat more back articulation as would be typical of /æ/
and 11 representing a closer and somewhat more fronted articulation
as would be typtical of /ɛ/),
`LevelEnglish` (`high`, `low` or `mid`),
`SelVowel1` (with 1 meaning that the participant selected /æ/
and 0 meaning that they selected /ɛ/),
and `ReactionTime` (not relevant for this exercise).

We would expect that the proportion of /æ/ selections drops
as `Step` gets closer to 11. Further, since English /æ/ tends
to be longer than English /ɛ/, we expect that the proportion
of /æ/ selections is greater for longer durations than
for shorter ones. Lastly, we expect that highly-proficient
participants are more sensitive to both of these cues.

Read in the data. Aggregate it in a sensible way
and visualise the aggregated data using a linechart
in such a way that it can be gauged whether these
expectations are borne out.
:::

# Putting it all together: Portuguese reading and writing skills

I'll walk you through this example in the lecture.
The data stem from @Lambelet_HELASCOT_writing and @Pestana_HELASCOT_reading.

::: {.callout-important}
## Drawing decent graphs can take time
Don't get disheartened by the lengthy code snippets below.
They are not the result of one energetic burst of coding.
As I'll try to demonstrate in the lecture, I started with a
fairly basic graph, found some problem with it, tried to fix it,
and so on. The end result is a plot with 27 boxplots that
hopefully enables readers to compare the three language groups
in terms of their test scores, to gauge the progress that each
language group makes from T1 to T3, and that also gives readers
a sense of the variation that exists within each group.
:::

```{r}
skills <- read_csv(here("data", "helascot_skills.csv"))
skills_longer_portuguese <- skills |> 
  pivot_longer(Reading:Narration,
               values_to = "score",
               names_to = "skill") |> 
  mutate(
    class = str_split_i(Subject, "_", 1),
    group = str_split_i(Subject, "_", 2)
  ) |> 
  mutate(language_group = case_when(
    group == "CP" ~ "Portuguese control",
    group == "CF" ~ "French control",
    group == "CD" ~ "German control",
    group %in% c("PLF", "PNF") ~ "French-Portuguese",
    group %in% c("PLD", "PND") ~ "German-Portuguese",
    .default =  "other"
  )) |> 
  filter(LanguageTested == "Portuguese")
```

```{r}
ggplot(skills_longer_portuguese |> 
         filter(!is.na(score)),
       aes(x = language_group,
           y = score)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitter(width = 0.2, height = 0),
             shape = 1,
             alpha = 1/5) +
  scale_x_discrete(limits = c("German-Portuguese", "French-Portuguese", "Portuguese control")) + 
  coord_flip() +
  facet_grid(rows = vars(Time),
             cols = vars(skill),
             scales = "free_x") +
  xlab(element_blank()) +
  ylab("Test score") +
  theme_bw()
```

# Cleveland dot plots

The three graphs below all show the same data
(the proportion of sales of a fictitious pie producer by pie taste).

```{r, eval = TRUE, echo = FALSE, fig.height = 4, fig.width = 12}
par(mfrow = c(1, 3), mar = c(8, 4, 2, 2), cex = 1.05)
pie.sales <- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)
names(pie.sales) <- c("Blueberry", "Cherry", "Apple", "Boston Cream", "Other", "Vanilla Cream")
pie.sales <- sort(pie.sales)
pie(pie.sales, main = "Pie chart")
par(las = 2)
barplot(pie.sales, main = "Bar chart", ylab = "Proportion of sales")
par(las = 1)
dotchart(pie.sales, xlab = "Proportion of sales", main = "Dot plot", pch = 16)
```

The graph on the left is a traditional **pie chart**.
Though common, this type of graph has serious shortcomings,
for which reason it should rarely be used:

1. Pie charts aren't very flexible: When the number of categories
is larger than here, pie charts are hardly comprehensible.
It's also difficult to add additional information to pie charts
(e.g., the proportion of sales by taste the year before; see below).

2. Readers gauge the numbers (in this case: the proportions)
that the pie chart represents less accurately than when they're 
presented in a bar chart or in a dot plot [@Cleveland1984].

The graph in the middle is a **bar chart**, the one of the right
a **dot plot**. Both are better choices than pie charts.
For one things, they're more flexible.
For instance, you can add the sales from the year before to
both graphs -- as separate bars or by using different symbols.
This would be difficult to accomplish in a pie chart:

```{r, eval = TRUE, echo = FALSE, fig.height = 4, fig.width = 10}
par(mfrow = c(1, 2), mar = c(8, 4, 2, 2), cex = 1.05)
pie.sales2015 <- c(0.08, 0.06, 0.18, 0.14, 0.35, 0.19)
names(pie.sales2015) <- names(pie.sales)
par(las = 1)
df.sales <- data.frame(Year2015 = pie.sales2015,
                       Year2016 = pie.sales)
rownames(df.sales) <- names(pie.sales)
par(las = 2)
barplot(height = t(as.matrix(df.sales)), 
        beside = TRUE, legend = TRUE,
        col = c("lightgrey", "grey20"),
        args.legend = list(x = "topleft"),
        ylab = "Proportion of sales", main = "Bar chart")
par(las = 1)
dotchart(pie.sales, xlab = "Proportion of sales", main = "Dot plot", xlim = c(0, 0.35))
points(x = pie.sales2015, y = 1:length(pie.sales2015), pch = 3)
legend("bottomright", pch = c(1, 3), legend = c("2016", "2015"))
par(mfrow = c(1,1))
```

I prefer dot plots because it's easier to visualise a large
number of categories and I find them less 'busy'.

::: {.callout-tip}
## Bars next to each other
If you prefer bar charts: It's usually better to plot the bars _next_ to each other rather than to stack them on _top_ of each other.
:::

::: {.callout-tip}
## Don't use pie charts
:::

## A basic Cleveland dot plot
For this tutorial, 
we'll use data from @Vanhove2017.
For this study, I recruited 175 native speakers of Dutch
from Belgium and the Netherlands. I showed them 44
German words with Dutch cognates 
(e.g., _Stadt_ (NL _stad_) or _Schiff_ (NL _schip_))
and asked them to choose their gender-marked definitive article 
(_der_ (masculine), _die_ (feminine), _das_ (neuter)).
Dutch and German are closely related languages, 
but there are a number of cognates whose grammatical gender
differs between both languages. The Dutch word _strand_ (beach),
for instance, is neuter, whereas the German word _Strand_ is
masculine.
One of the research questions was if Belgian and Dutch participants
were more likely to choose the neuter article _das_ if the German word's
Dutch cognate is neuter than when it has common gender. 
(Common gender = non-neuter. Present-day Standard Dutch hardly distinguishes between masculine and feminine gender.)

```{r}
d_dot <- read_csv(here("data", "GermanArticleChoices.csv"))
```

The column `NeuterResponses` contains the proportion of neuter article
(_das_)
choices per German word (`Stimulus`) per (`Country`).
The column `GermanGender` contains the word's correct gender (in German);
the column `DutchGender` contains the grammatical gender of the word's Dutch cognate.

We can plot the proportion of _das_ choices per word 
separately per country
(Belgium vs. the Netherlands).
This will show us how strongly the response pattern varies per word
and whether Belgian and Dutch speakers of Dutch show different preferences.
Note that I put the word labels along the y-axis, which makes them much easier
to read, and the proportion of neuter responses along the x-axis.

```{r, fig.asp = 1.2}
ggplot(d_dot,
       aes(x = NeuterResponses,
           y = Stimulus,
           shape = Country)) + 
  geom_point() 
```


The plot above doesn't offer an answer to the research question
since the difference between stimuli with different Dutch genders
isn't highlighted.
To accomplish this, we can plot stimuli with neuter cognates and
those with common-gender cognates in different boxes (_facetting_,
see the tutorial on line charts).
(To see what `scales = "free_y"` and `space = "free_y"` accomplish, 
leave these parameters out of the call, i.e., just use ` facet_grid(rows = vars(DutchGender))`.)

```{r, fig.asp = 1.2}
ggplot(d_dot,
       aes(x = NeuterResponses,
           y = Stimulus, 
           shape = Country)) + 
  geom_point() + 
  facet_grid(rows = vars(DutchGender),
             scales = "free_y",
             space = "free_y")
```

This graph shows pretty clearly that both Belgian and Dutch
speakers of Dutch pick _das_ more often if the German word
has a neuter-gender cognate than when it has a common-gender
cognate: The points in the lower box lie more to the right
than those in the upper box. With a single exception (_Boot_),
there is no overlap between these two distributions.

Additionally, the responses of Belgian and Dutch participants
don't seem to vary much from one another.
For instance, we don't observe that most triangles lie to the
right of the circles or that Belgian participants prefer _das_ for _Wurst_
and Dutch participants don't.

## Finishing touches
The previous graph is good enough. But we can do better still.
German is taught in school in both Flanders and the Netherlands,
and at least some participants will have known which words are
neuter in German and which aren't.
So some of the variation between the stimuli will be attributable
to the stimuli's German gender.
To highlight this, we can split up the graph not only by
the words' Dutch gender, but also by their German gender.
And we still have to label the axes!

```{r, fig.asp = 1.2}
ggplot(d_dot,
       aes(x = NeuterResponses, 
           y = Stimulus,
           shape = Country)) +
  geom_point() +
  facet_grid(rows = vars(DutchGender, GermanGender),
             scales = "free_y", space = "free_y") +
  xlab("Proportion 'das'") +
  ylab(element_blank())
```

The upper three boxes show feminine, masculine and neuter
German words with common-gender cognates; the lower three boxes
show feminine, masculine and neuter German words with neuter-gender
cognates.
The graph shows that the factor _Dutch gender_ is the most important
determinant of the participants' article choices. But the factor
_German gender_ also plays a role: When a German word is neuter,
both Belgian and Dutch people choose _das_ more often than when
it's feminine or masculine.

* Now the words are sorted alphabetically in each box. But this order can be customised. We can also add to the word labels the words' Dutch counterparts.
* We could reorder the facets so that the word categories that result in the most 'das' responses are at the top of the graph. While we're at it, we could also give these facets clearer labels.
* The symbols used in the graph above are difficult to distinguish optically. They, too, can be changed.

```{r, fig.asp = 1.4}
d_dot <- d_dot |> 
  # Clearer labels
  mutate(
    word_label = paste0(Stimulus, " (", DutchCognate, ")"),
    dutch_label = paste0("Du.: ", DutchGender),
    german_label = paste0("Gm.: ", GermanGender)
  ) |> 
  # Reorder the labels by proportion 'das'
  mutate(
    word_label = reorder(word_label, NeuterResponses),
    dutch_label = reorder(dutch_label, NeuterResponses),
    german_label = reorder(german_label, NeuterResponses)
  )

ggplot(d_dot,
       aes(x = NeuterResponses,
           y = word_label,
           shape = Country)) +
  geom_point() +
  xlab("Proportion of neuter (das) choices") +
  ylab("German noun") +
  scale_shape_manual(values = c(1, 3)) +
  facet_grid(rows = vars(dutch_label, german_label),
             scales = "free_y",
             space = "free_y") +
  theme_bw()
```

Hm. The facets with more 'das' responses are at the bottom of the graph,
whereas within each facet, the words with more 'das' responses are at the top.
We can fix this by setting the `decreasing` parameter in the `reorder()` function.
We also put the legend at the bottom of the graph and slightly increase the 
size of the symbols:

```{r, fig.asp = 1.42}
d_dot <- d_dot |> 
  # Reorder the gender labels in decreasing order by proportion 'das'
  mutate(
    dutch_label = reorder(dutch_label, NeuterResponses, decreasing = TRUE),
    german_label = reorder(german_label, NeuterResponses, decreasing = TRUE)
  )

ggplot(d_dot,
       aes(x = NeuterResponses,
           y = word_label,
           shape = Country)) +
  geom_point(size = 2) +
  xlab("Proportion of neuter (das) choices") +
  ylab("German noun") +
  scale_shape_manual(values = c(1, 3)) +
  facet_grid(rows = vars(dutch_label, german_label),
             scales = "free_y",
             space = "free_y") +
  theme_bw() +
  theme(legend.position = "bottom")
```

Not half bad, I think.

::: {#exr-dotplot}
## Another dotplot
In @Vanhove2016,
native speakers of German who hadn't learnt
Dutch yet were assigned to one of two
learning conditions (_oe--u_ and _ij--ei_), in which they
were exposed to Dutch--German cognates exhibiting
the grapheme correspondences oe--u (e.g., _hoed_--_Hut_)
and ij--ei (e.g., _wijn_--_Wein_), respectively.
I then asked them to translate previously unseen
Dutch words containing these digraphs. 
The question was quite simply, if the participants
who had been exposed to the oe--u correspondence
but not to the ij--ei correspondence would be more likely
to translate Dutch words containing _oe_ as German words
containing _u_ than the participants who had been
exposed to the ij--ei correspondence but not to the oe--u
correspondence, and similarly for the other way round.

The data are laid out in three data sets:

* `Vanhove2016_subjects.csv` contains information about
the participants, including the `LearningCondition`
to which they were assigned; 
* `Vanhove2016_items.csv` contains information about the items, including the `Category` to which they belong (`ij cognate`, `oe cognate`, `other cognate`, `non-cognate`);
* `Vanhove2016_translations.csv` shows how the subjects translated each item and how these translations were scored. The relevant outcome is `CorrectVowel`.

Read in and merge these three datasets.
Then draw a dotchart similar to the one above that shows, for each 
Dutch word containing _oe_ or _ij_, the 
proportion of participants in each condition that used the correct vowel
when translating it. You can ignore the items in the categories `other cognate`
and `non-cognate` as well as the items occurring in the `Training` `Block`.
Interpret the results.

Bonus: Aggregate the data in a different way, namely by computing the
proportion of correct vowel uses per participant per item category.
(You should again ignore the categories `other cognate` and `non-cognate`
as well as the `Training` `Block`.)
Visualise these aggregated data, for stance using boxplots. 
Do you see any advantages and disadvantages of this visualisation compared to the dotchart?
Would it be useful to include both kinds of visualisation when presenting
the study's results at a conference or in a research paper?
:::


# Scatterplots
For my PhD thesis [@Vanhove2014],
I investigated how people's ability to
recognise written and spoken cognates in a related but
unknown language develops throughout the lifespan and
how it is related to linguistic and cognitive factors.
The dataset `Vanhove2014_Translations.csv` contains the
_raw data_ of this study. For each of the 163 participants,
this dataset contains 100 entries (one for each cognate),
for a total of 16,300 rows.
Each translation was rated as correct or incorrect.
Additionally, the dataset contains some information
about the participants (e.g., their performance on other
tasks) as well as about the stimuli (e.g., a measure
expressing its formal similarity to its French, German or English cognate).

```{r}
d_scatter <- read_csv(here("data", "Vanhove2014_Translations.csv"))
```

The variables:

* `Stimulus`: The word to be translated.
* `Subject`: The participant's ID.
* `Mode`: Whether the word was presented in its spoken (`Auditory`) or in its written form (`Visual`).
* `Trial`: The position of the word in the task.
* `Translation`: The participant's translation attempt for the stimulus.
* `Correct`: Whether the translation was correct (1) or incorrect (0).
* `Sex`
* `Age`
* `NrLang`: The number of languages the participant spoken.
* `DS.Total`: The participant's score on a working memory task.
* `WST.Right`: The participant's score on a German vocabulary test.
* `Raven.Right`: The participant's score on an intelligence test.
* `English.Total`: The participant's score on an English-language test.
* `Status`: Whether the stimulus has a German, English, or French cognates (`target`) or not (`profile`).
* `MinLev`: The degree of formal discrepancy between the stimulus and its most similar German, English or French cognate. (lower = more similar)

Missing values were labelled `NA` (not available).

A rough summary can be obtained like so:

```{r}
summary(d_scatter)
```

In order to be able to sensibly visualise these data,
we need to first transform this dataset. If we're interested
in the relationship between the participants' age, sex,
and linguistic and cognitive test results on the one hand
and their translation performance on the other hand,
it seems useful to first compute the number of correct
translations for spoken and written words per participant.
To this end, we can use the tools introduced in the Datasets part of this lecture.
Note that we `group_by()` not just `Subject` and `Mode`, but also by a
bunch of participant-related variables. This way, we don't need to construct
a tibble with these variables and then join it with the summary data:

```{r}
per_participant <- d_scatter |> 
  # Only interested in cognates ('target')
  filter(Status == "target") |> 
  group_by(Subject, Age, Sex, WST.Right, Raven.Right, English.Total,
           NrLang, DS.Total, Mode) |> 
  summarise(nr_correct = sum(Correct),
            .groups = "drop")
```

To investigate the relationhip between, say, `WST.Right` and `number_correct`,
we can plot these data in a scatterplot. While we're at it, we can split up
this graph into two panels: one for written words, and one for spoken words.

```{r, fig.asp = 0.5}
ggplot(dat = per_participant,
       aes(x = WST.Right, 
           y = nr_correct)) +
  geom_point(shape = 1) +
  xlab("L1 vocabulary test") +
  ylab("Number of correct translations\n(out of 45)") +
  facet_grid(cols = vars(Mode)) +
  theme_bw()
```

The warning concerns missing values in the `WST.Right` variable:
```{r}
per_participant |> 
  filter(is.na(WST.Right))
```
While only one participant had a missing `WST.Right` value,
this participant is represented twice in the dataset (once for auditory stimuli,
once for written stimuli), hence the two warnings.

As for the decision which variable to put along which axis.
By and large, put the variable that is most likely to be the _cause_
of the relationship along the _x_ axis and the variable that is most
likely to be the _effect_ along the _y_ axis. In this case,
it seems more likely that L1 skills affect one's ability to recognise
cognates in a foreign language than vice versa. Hence, put 
the variable representing L1 skills along the _x_ axis.

::: {.callout-important}
## No correlations without scatterplots!
Relations between two numeric variables are often summarised by means of
a correlation coefficient. It's important to appreciate that any correlation
coefficient can correspond to a multitude of underlying data patterns.
Crucially, correlation coefficients close to 0 do not have to mean that there
is no relation between the two numeric variables (the relation may be
strongly nonlinear), and correlation coefficients close to 1 (or -1) don't have
to mean that there is a strong relation between the two numeric variables
(the correlation may be driven by an outlier, among other possibilities).

By way of illustration, all of the plots in the first figure below show 30 observations
of two variables with a sample correlation of $r = 0.8$, whereas all of the plots
in the second figure below show 60 observations of two variables with a sample
correlation of $r = 0$.
For details, see the blog post [_What data patterns can lie behind a correlation coefficient?_](https://janhove.github.io/posts/2016-11-21-what-correlations-look-like/index.html)
as well as the article [_Towards simpler and more transparent quantitative research reports_](https://doi.org/10.1075/itl.20010.van) [[preprint]](https://doc.rero.ch/record/328689).

```{r, echo = FALSE, fig.asp = 1}
library(cannonball)
plot_r(r = 0.8, n = 30)
plot_r(r = 0, n = 60)
```

So, whenever you want to compute a correlation coefficient, 
**draw a scatterplot first**. And show it to your readers.
:::

## Trendlines
Consider the following scatterplots:

```{r, fig.asp = 0.5}
ggplot(dat = per_participant,
       aes(x = English.Total, 
           y = nr_correct)) +
  geom_point(shape = 1) +
  xlab("Result English test") +
  ylab("Number of correct translations") +
  facet_grid(cols = vars(Mode))
```

We can add scatterplot smoothers to these plots by means of `geom_smooth()`.
Scatterplot smoothers were developed to discover relationships
(including nonlinear ones) between two variables that aren't
necessarily immediately obvious if the data are shown in a 
scatterplot. Here I turn off the confidence band around the scatterplot smoother
(`se = FALSE`) as confidence bands are a topic well beyond the scope of this primer.

```{r, fig.asp = 0.5}
ggplot(dat = per_participant,
       aes(x = English.Total, 
           y = nr_correct)) +
  geom_point(shape = 1) +
  geom_smooth(se = FALSE) + 
  xlab("Result English test") +
  ylab("Number of correct translations") +
  facet_grid(cols = vars(Mode))
```


The points on the smoother are a kind of **mean value of the $Y$ variable for the respective $X$ value**.
In the left panel, for instance, the average number of correct translations in the auditory mode for someone with an English test score of 30 is roughly 17--18,
whereas the average number of correct translations for written words for participants with a score of 40 on the English test is about 25.

We needn't necessarily amuse ourselves with the maths behind these smoothers 
(but check out the info box if you're curious),
but the following points are important:

1. The trend line is nearly always a bit _wiggly_. 
This is the case even when the relationship itself is as good as linear.

2. The default settings for `geom_smooth()` tend to work fairly well, but sometimes it's necessary to fiddle with them so that the smoother captures the trend in the data better.

To elaborate on the second point, consider the graph below, which shows 
a scatterplot of simulated data with two scatterplot smoothers.
The red line was drawn with the default settings. This line doesn't capture an important feature of the relationship (the data points go up and down). 
The blue line captures this trend much better. It was drawn using the command `geom_smooth(span = 0.1)`. The `span` parameter determines how wiggly the curve may be (the smaller `span`, the wigglier the curve). By default, span is set to 0.75. Finding a decent span value is matter of trial and error.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
df <- data.frame(x = runif(100, -4*pi, 4*pi))
df$y <- sin(df$x) + 0.2*df$x + rnorm(50, sd = 0.1)
ggplot(dat = df,
       aes(x = x, y = y)) +
  geom_point(pch = 1) +
  geom_smooth(colour = "red", se = FALSE, lwd = 0.5,
              method = "loess") +
  geom_smooth(span = 0.1, colour = "blue", se = FALSE, lwd = 0.5,
              method = "loess")
```

In the second example, the blue line was drawn
using `geom_smooth(span = 0.1)`.
This line is much too wiggly, and it essentially 
models random deviations from the general trend.
The red line, drawn with the default setting (`span = 0.75`),
captures the general trend much more sensibly.
The _green_ line, by contrast, isn't wiggly enough (`span = 3`).

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.asp = 0.3}
set.seed(21-11-2016)
df <- data.frame(x = runif(100, -4*pi, 4*pi))
df$y <- 3*df$x^3 - 0.2*df$x^2 - 50*df$x + rnorm(50, sd = 1000)
p1 <- ggplot(dat = df,
       aes(x = x, y = y)) +
  geom_point(pch = 1) +
  geom_smooth(span = 0.1, colour = "blue", se = FALSE, lwd = 0.5, method = "loess")
p2 <- ggplot(dat = df,
       aes(x = x, y = y)) +
  geom_point(pch = 1) +
  geom_smooth(span = 0.75, colour = "red", se = FALSE, lwd = 0.5, method = "loess")
p3 <- ggplot(dat = df,
       aes(x = x, y = y)) +
  geom_point(pch = 1) +
  geom_smooth(span = 3, colour = "darkgreen", se = FALSE, lwd = 0.5, method = "loess")
gridExtra::grid.arrange(p1,p2,p3,ncol=3)
```

**Summing up:** Generally, the default settings work reasonably well. But when you notice that visually salient patterns
in the scatterplot aren't captured by the trend line,
you need to fiddle a bit with the `span` parameter.

More generally, data analysis and statistics aren't a matter of
blindly applying formulae and recipes.

::: {.callout-note}
## Trend line techniques
By default, `geom_smooth()` draws the trend line using 
the LOESS (_locally estimated scatterplot smoothing_) technique for
datasets with fewer than 1,000 observations and uses a GAM
(_generalised additive model_) for larger datasets.
Alternatives are simple linear regression (`method == "lm"`) 
and robust linear regression (`method == "rlm"`).
We can't discuss all of these techniques in this primer, 
but LOESS works roughly as follows.

Let $X = (X_1, \dots, X_n)$ be a data vector of predictor values
and let $Y = (Y_1, \dots, Y_n)$ be a data vector of outcome values.
We specify a positive value for the `span` parameter, 
also referred to as $\alpha$. Typically, $\alpha \in (0, 1)$, and we will restrict our attention to this case.
If we want to evaluate the LOESS smoother at a given value $x_*$,
we first compute the distances between the observed predictor values
and $x_*$:
$$d_i = |X_i - x_*|$$
for $i = 1, \dots, n$. 
We sort the distances ascendingly and read out the smallest distance
such that at least $\alpha \cdot n$ of the distances are no larger than it.
Call this distance $M$.
Next, for each data point, we compute a weight:
$$w_i = \begin{cases}\left(1 - \left(\frac{d_i}{M}\right)^3\right)^3 & \textrm{if $d_i \leq M$}, \\ 0 & \textrm{else},\end{cases}$$
for $i = 1, \dots, n$.
This weighting scheme assigns large weights to data points with predictor values
close to $x_*$ and smaller ones with predictor values farther away from $x_*$.
Data points with predictor values larger than $M$, i.e., data points that do not
belong to the closest $100\alpha$% of data points to $x_*$ get weight 0.
That is, the smaller $\alpha$, the more the LOESS fit is based on local information,
and the larger $\alpha$, the more it uses global information.
Next, a weighted polynomial regression model is fitted to the data.
By default, quadratic regression is used, which means that we 
we compute the values $\widehat{b}_0, \widehat{b}_1, \widehat{b}_2$
that minimise the weighted sum of squares
$$\sum_{i=1}^n w_i(Y_i - (\widehat{b}_0 + \widehat{b}_1X_i + \widehat{b}_2X_i^2))^2.$$
Finally, we evaluate the smoother at $x_*$ as
$$\widehat{b}_0 + \widehat{b}_1x_* + \widehat{b}_2x_*^2.$$
The `loess()` function that `geom_smooth()` draws on implements a few improvements
on this procedure.
:::

::: {#exr-age}
## Age trends
Still using the data from @Vanhove2014, 
visualise the relationship between the participants'
age and their performance on the cognate translation task
in both modalities. How would you describe the age trends?

Only if you know about regression modelling:
Would you use simple linear regression to capture these
age trends? Why or why not?
:::

::: {#exr-schlechtweg2}
## Scatterplots for binary data
Sscatterplots can also be useful
if you have a binary outcome variable and a continuous predictor.
To illustrate this, we revisit the data from the study by @Schlechtweg2023, see
@exr-schlechtweg1.

1. Read in the data.
2. Retain only the data for Subject 42.
3. Draw a scatterplot (with a smoother) that shows the `Step` variable along the x-axis and the `SelVowel1` (i.e., whether the sound was identified as /æ/) along the y-axis. Use a tiny amount of vertical jittering (see the section on boxplots) so that we can make out overlapping data points, and use facetting to split up the plot by `Duration`.
4. Interpret the graph.

In this example, the binary outcome `SelVowel1` was already coded as a numeric variable
with values 0 and 1.
If it had been coded as a character variable with values, say, /æ/ and /ɛ/, you would have to
assign the value of 0 to one level of the variable and 1 to the other one.

5. Now use the data for all participants, but only plot the data for sounds of `middle` duration.
Use `facet_wrap(vars(Subject))` to split up the plot by subjects. Interpret the graph in terms of the main trend. Are there many subjects that seem to buck the trend?

6. @Schlechtweg2023 also collected data on how strongly their participants distinguish between
the German sounds /e:/ (_denen_) and /ɛ:/ (_Dänen_). Participants with `GermanPillai` scores near 1 strongly disambiguate between these sounds in their German production; those with `GermanPillai` scores near 0 have merged these sounds in their own German production. Instead of facetting by `Subject`, facet by `reorder(Subject, GermanPillai)`. Then the plots will be arranged from left to right, top to bottom in increasing order of the participants' `GermanPillai` scores. Is there some evidence that the participants' vowel selections in L2 English depend on how strongly they disambiguate between the two German sounds?

7. Using the same lay-out as for the previous plot (i.e., facetting by subject, order by `GermanPillai`), draw plots showing the trendlines per subject for sounds of short, middle, and long duration. Use different colours for the different durations. Don't plot the individual data points, as they would overload the plots. Can you observe any trends? For instance, is one duration typically associated with more /æ/ selections than the others?
:::

## The Tukey mean--difference plot
Within-subjects studies are studies in which the participants are tested
in several (typically all) conditions rather than just one as in the case
of between-subjects studies.
Data from within-subjects studies are often difficult to visualise satisfactorily:
While you could draw boxplots that show the participants' performance in the 
different conditions, these plots don't show which data points belong to the same
participants. Yet this information could be crucial: Are the top performers
in one condition also the top performers the other conditions (suggesting that
the conditions don't affect relative performance) or are the top performers
in one condition the bottom performers in the other conditions (suggesting that
the conditions are differently suited to different profiles)?
One option is to add lines connecting the data points for each participant,
but such plots get overloaded pretty quickly.

In the special but common case of a within-subjects design with just two conditions,
the Tukey mean--difference plot (also known as the Bland--Altman plot in medical circles)
is a useful alternative. For each participant, we compute the average of their
two condition scores as well as the difference between these two scores.
We then draw a scatterplot and put the averages along the x-axis
and the differences along the y-axis.
If the scores in one condition are generally better than in the other condition,
it should either be the case that most scores lie above 0 or that most scores lie beneath 0.
Further, if there is no noticeable pattern in the scatterplot, this suggests
that the difference between the condition is pretty consistent across all performance levels.
If, however, the scatterplot shows, say, a downward trend, this would mean that
the top performers don't derive the same benefit from the other condition
as the other participants do.

**EXAMPLE?**

# Scatterplot matrices
Scatterplot matrices are useful for showing the bivariate relationships
among multiple variables. I usually use a custom function, `scatterplot_matrix()`,
to plot such scatterplot matrices. To use this function, load the `scatterplot_matrix.R`
file that you've put in the `functions` subdirectory:

```{r}
source(here("functions", "scatterplot_matrix.R"))
```


Let's look at an example. We read in the lexical metrics data and text ratings
from the French/German/Portuguese project (see the Datasets primer), compute the average rating per text,
and plot the relationships between the average rating, the number of tokens in the texts
as well as the texts' type/token ratio in a scatterplot matrix:

```{r}
metrics <- read_csv(here("data", "helascot_metrics.csv"))
ratings <- read_csv(here("data", "helascot_ratings.csv"))
rating_per_text <- ratings |> 
  group_by(Text, Subject, Text_Language, Text_Type, Time) |> 
  summarise(mean_rating = mean(Rating),
            n_ratings = n(),
            .groups = "drop")
metrics_ratings <- metrics |> 
  left_join(rating_per_text)

# draw scatterplot matrix
metrics_ratings |> 
  filter(Text_Type == "arg") |> 
  filter(Text_Language == "Portuguese") |> 
  filter(Time == 2) |> 
  mutate(log2.nTokens = log2(nTokens)) |> 
  select(mean_rating, TTR, log2.nTokens) |> 
  scatterplot_matrix(labels = c("mean rating", "type/token ratio", "nr. tokens (log-2)"))
```

On the main diagonal, we see a histogram for each variable
as well as the number of data points that each histogram is based on.
Here, we have $n = 180$ for all histograms. But if you have missing data
for some variables, these numbers will vary.

In the top triangle, we see scatterplots (including scatterplot smoothers)
for the three bivariate relatonships. The scatterplot in the $(i,j)$-th cell
shows the relationship between the variable whose histogram
is shown in the $i$-th row (along the y-axis) and the variable whose histogram is shown in
the $j$-th column (along the x-axis). That is, the top right scatterplot
shows the relation between the number of tokens (log-2 transformed, on the x-axis)
and the mean rating (along the y-axis).

In the bottom triangle, the Pearson correlation coefficients for these
relationships are shown, along with the number of data points it is based on.
For instance, the number -0.15 is the correlation between the mean ratings and the
type/token ratios, whereas 0.70 is the correlation between the mean ratings and the number
of tokens (log-2 transformed).

Incidentally, I transformed the number of tokens because this variable
was pretty right-skewed. If the log-2 transformed value is 4, then 
the original value is $2^4 = 16$; if the log-2 transformed value is 6,
then the original value is $2^6 = 64$. 

An alternative to `scatterplot_matrix()` is the `ggpairs()` function
from the [`GGally` package](https://ggobi.github.io/ggally/reference/ggpairs.html).


# Suggested reading
Kieran Healy's _Data visualization: A practical introduction_ does a stirling
job at explaining the _why_ and the _how_ of drawing graphs using `R` 
and the `tidyverse`.
In addition to the material covered in this lecture, Healy covers drawing
maps and drawing visualisations of statistical models.
The entire book is freely available from [socviz.co](https://socviz.co/).

As their name suggests, Cleveland dot plots were popularised by
@Cleveland1993 in his book _Visualizing data_.
But if you want to learn more about this flexible visualisation tool,
I suggest you check out the article by @Soenning2016,
which is geared towards linguists.

# Software versions

```{r}
devtools::session_info(pkgs = "attached")
```

